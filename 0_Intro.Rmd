---
title: "0. Introduction"
author: "G. Versteeg (based on Edgar Ruiz)"
date: "29/01/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, echo = TRUE,
                      cache = TRUE, dpi = 180, fig.width = 8, fig.height = 5)
library(randomForest)
library(ranger)
library(tidyverse)
library(tidymodels)
```

## Introduction
We will use the `iris` data set for an example. Its data is already imported, and sufficiently tidy to move directly to modeling.
For his example, we use only one package i.e., `tidymodels`. 
Apart from loading its core modeling packages, `tidymodels` also conveniently loads some `tidyverse` packages, including `dplyr` and `ggplot2`. Throughout this exercise, we will use some functions out of those packages, but we don’t have to explicitly load them into our R session.


## Pre-processing the data

This step focuses on making data suitable for modeling by using data transformations. All transformations can be accomplished with `dplyr`, or other `tidyverse` packages. Consider using `tidymodels` packages when model development is heavier and more complex.

### Data Sampling
The `initial_split()` function is specially built to separate the data set into a training and testing set. By default, it holds 3/4 of the data for training and the rest for testing. That can be changed by passing the `prop` argument. This function generates a `rsplit` object, not a data frame. The printed output shows the row count for testing, training, and total.

To access the observations reserved for training, use the `training()` function. Similarly, use `testing()` to access the testing data. These sampling functions are courtesy of the `rsample` package, which is part of `tidymodels`.


```{r sampling}
iris_split <- initial_split(iris, prop = 0.6)
iris_split

iris_split %>%
  training() %>%
  glimpse()

```

## Pre-processing interface

### Defining the pre-processing in a recipe

In `tidymodels`, the `recipes` package provides an interface that specializes in data pre-processing. Within the package, the functions that start, or execute, the data transformations are named after cooking actions. That makes the interface more user-friendly. For example:

* `recipe()` - Starts a new set of transformations to be applied, similar to the `ggplot()` command. Its main argument is the model’s formula.
* `prep()` - Executes the transformations on top of the data that is supplied (typically, the training data).

Each data transformation is a step. Functions correspond to specific types of steps, each of which has a prefix of `step_`. There are several `step_` functions; in this example, we will use three of them:

* `step_corr()` - Removes variables that have large absolute correlations with other variables
* `step_center()` - Normalizes numeric data to have a mean of zero
* `step_scale()` - Normalizes numeric data to have a standard deviation of one

Another nice feature is that the step can be applied to a specific variable, groups of variables, or all variables. The `all_outcomes()` and `all_predictors()` functions provide a very convenient way to specify groups of variables. For example, if we want the `step_corr()` to only analyze the predictor variables, we use `step_corr(all_predictors())`. This capability saves us from having to enumerate each variable.


```{r define_recipe}
iris_recipe <- training(iris_split) %>%
  recipe(Species ~.) %>%
  step_corr(all_predictors()) %>%
  step_center(all_predictors(), -all_outcomes()) %>%
  step_scale(all_predictors(), -all_outcomes()) %>%
  prep()


iris_recipe

```

In the above code, we have put together the `recipe()`, `prep()`, and `step` functions to create a `recipe` object. The `training()` function is used to extract that data set from the previously created split sample data set.
Calling the `iris_recipe` object, it will print details about the recipe. The Operations section describes what was done to the data. One of the operations entries in the example explains that the correlation step removed the `Petal.Length` variable.


### Executing the pre-processing recipe

The testing data can now be transformed using the exact same steps, weights, and categorization used to pre-process the training data. To do this, another function with a cooking term is used: `bake()`. Notice that the `testing()` function is used in order to extract the appropriate data set.

```{r execute recipe_1}
iris_testing <- iris_recipe %>%
  bake(testing(iris_split)) 

glimpse(iris_testing)

```

Performing the same operation over the training data is redundant, because that data has already been prepped. To load the prepared training data into a variable, we use `juice()`. It will extract the data from the `iris_recipe` object.

```{r execute recipe_2}
iris_training <- juice(iris_recipe)

glimpse(iris_training)

```

Note. `glimpse()` is like a transposed version of `print()`: columns run down the page, and data runs across. This makes it possible to see every column in a data frame. It's a little like `str()` applied to a data frame but it tries to show you as much data as possible. And it always shows the underlying data, even when applied to a remote data source.

`glimpse(x, width = NULL, ...)`

Arguments
* x	- An object to glimpse at.
* width -	Width of output: defaults to the setting of the option
	tibble.width (if finite) or the width of the console.

## Model Training

In R, there are multiple packages that fit the same type of model. It is common for each package to provide a unique interface. In other words, things such as an argument for the same model attribute is defined differently for each package. For example, the `ranger` and `randomForest` packages fit Random Forest models. In the `ranger()` function, to define the number of trees we use `num.trees`. In `randomForest`, that argument is named `ntree`. It is not easy to switch between packages to run the same model.

Instead of replacing the modeling package, `tidymodels` replaces the interface. Better said, `tidymodels` provides a single set of functions and arguments to define a model. It then fits the model against the requested modeling package.

In the example below, the `rand_forest()` function is used to initialize a Random Forest model. To define the number of trees, the `trees` argument is used. To use the ranger version of Random Forest, the `set_engine()` function is used. Finally, to execute the model, the `fit()` function is used. The expected arguments are the formula and data. Notice that the model runs on top of the juiced trained data.

```{r training_1}
iris_ranger <- rand_forest(trees = 100, mode = "classification") %>%
  set_engine("ranger") %>%
  fit(Species ~ ., data = iris_training)

```

The payoff is that if we now want to run the same model against `randomForest`, we simply change the value in `set_engine()` to “randomForest”.

```{r training_2}
iris_rf <-  rand_forest(trees = 100, mode = "classification") %>%
  set_engine("randomForest") %>%
  fit(Species ~ ., data = iris_training)

```

It is also worth mentioning that the model is not defined in a single, large function with a lot of arguments. The model definition is separated into smaller functions such as `fit()` and `set_engine()`. This allows for a more flexible - and easier to learn - interface.

## Predictions

Instead of a vector, the `predict()` function ran against a `parsnip` model returns a `tibble`. By default, the prediction variable is called `.pred_class`. In the example, notice that the baked testing data is used.

```{r prediction_1}
predict(iris_ranger, iris_testing)

```

It is very easy to add the predictions to the baked testing data by using dplyr’s `bind_cols()` function.

```{r prediction_2}
iris_ranger %>%
  predict(iris_testing) %>%
  bind_cols(iris_testing) %>%
  glimpse()

```

## Model Validation

Use the `metrics()` function to measure the performance of the model. It will automatically choose metrics appropriate for a given type of model. The function expects a `tibble` that contains the actual results (`truth`) and what the model predicted (`estimate`).

```{r validate_1}
iris_ranger %>%
  predict(iris_testing) %>%
  bind_cols(iris_testing) %>%
  metrics(truth = Species, estimate = .pred_class)

```

Because of the consistency of the new interface, measuring the same metrics against the `randomForest` model is as easy as replacing the model variable at the top of the code.

```{r validate_2}
iris_rf %>%
  predict(iris_testing) %>%
  bind_cols(iris_testing) %>%
  metrics(truth = Species, estimate = .pred_class)

```

### Per classifier metrics

It is easy to obtain the probability for each possible predicted value by setting the `type` argument to `prob`. That will return a `tibble` with as many variables as there are possible predicted values. Their name will default to the original value name, prefixed with `.pred_`.

```{r metrics_1}
iris_ranger %>%
  predict(iris_testing, type = "prob") %>%
  glimpse()

```

Again, use `bind_cols()` to append the predictions to the baked testing data set.


```{r metrics_2}
iris_probs <- iris_ranger %>%
  predict(iris_testing, type = "prob") %>%
  bind_cols(iris_testing)
glimpse(iris_probs)

```

### Curve metrics

Now that everything is in one `tibble`, it is easy to calculate curve methods. In this case we are using `gain_curve()`.

```{r metrics_3}
iris_probs%>%
  gain_curve(Species, .pred_setosa:.pred_virginica) %>%
  glimpse()

```

The curve methods include an `autoplot()` function that easily creates a `ggplot2` visualization.

```{r metrics_4}
iris_probs%>%
  gain_curve(Species, .pred_setosa:.pred_virginica) %>%
  autoplot()

```

This is an example of a `roc_curve()`. Again, because of the consistency of the interface, only the function name needs to be modified; even the argument values remain the same.


```{r metrics_5}
iris_probs%>%
  roc_curve(Species, .pred_setosa:.pred_virginica) %>%
  autoplot()

```

### Model metrics

To measure the combined single predicted value and the probability of each possible value, combine the two prediction modes (with and without `prob` type). In this example, using dplyr’s `select()` makes the resulting `tibble` easier to read.

```{r metrics_6}
predict(iris_ranger, iris_testing, type = "prob") %>%
  bind_cols(predict(iris_ranger, iris_testing)) %>%
  bind_cols(select(iris_testing, Species)) %>%
  glimpse()

```

Pipe the resulting table into `metrics()`. In this case, specify `.pred_class` as the estimate.

```{r metrics_7}
predict(iris_ranger, iris_testing, type = "prob") %>%
  bind_cols(predict(iris_ranger, iris_testing)) %>%
  bind_cols(select(iris_testing, Species)) %>%
  metrics(Species, .pred_setosa:.pred_virginica, estimate = .pred_class)

```
